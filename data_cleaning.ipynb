{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to clean, reduce, transform and discretize the supporting data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: This function loads data from a csv file and return a pandas dataframe\n",
    "Parameters: Path to file to be loaded\n",
    "Returns: Pandas dataframe\n",
    "'''\n",
    "def loadData(file):\n",
    "    df = pd.read_csv(file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: This function pickles a pandas dataframe\n",
    "Parameters: Pandas dataframe and path of pickle file\n",
    "Returns: N/A\n",
    "'''\n",
    "def pickleDataFrame(df,file):\n",
    "    #with open(file,'w+') as f:\n",
    "    df.to_pickle(file, compression='gzip', protocol=4)\n",
    "    print(\"Pickling to file - %s complete.\" %file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(df_list):\n",
    "    for df_key in df_list.keys():\n",
    "        if(df_key == 'facilities'):\n",
    "            df = df_list[df_key][['common_name','address','longitude','latitude']]\n",
    "            df = df.dropna()\n",
    "            print(df.dtypes)\n",
    "            #pickleDataFrame(df,'store/facilities.pkl')\n",
    "        elif(df_key == 'private_open_spaces'):\n",
    "            df = df_list[df_key][['NAME', 'the_geom', 'LOCATION']]\n",
    "            df = df.dropna()\n",
    "            print(df['the_geom'])\n",
    "            #print(df.head(3))\n",
    "            #print(df.dtypes)\n",
    "            #pickleDataFrame(df,'store/private_spaces.pkl')\n",
    "        elif(df_key == 'colleges'):\n",
    "            df = df_list[df_key][['Institution', 'Address', 'Location']]\n",
    "            df = df.dropna()\n",
    "            print(df.head(3))\n",
    "            print(df.dtypes)\n",
    "            #pickleDataFrame(df,'store/colleges.pkl')\n",
    "        elif(df_key == 'public_open_spaces'):\n",
    "            df = df_list[df_key][['ParkName', 'Location 1']]\n",
    "            df = df.dropna()\n",
    "            print(df.head(3))\n",
    "            print(df.dtypes)\n",
    "            #pickleDataFrame(df,'store/public_open_spaces.pkl')\n",
    "        elif(df_key == 'commuter_stops'):\n",
    "            df = df_list[df_key][['LOCATION', 'LATITUDE', 'LONGITUDE', 'PARKINGTYP']]\n",
    "            df = df.dropna()\n",
    "            print(df.head(3))\n",
    "            print(df.dtypes)\n",
    "            #pickleDataFrame(df,'store/commuter_stops.pkl')   \n",
    "        elif(df_key == 'public_park'):\n",
    "            df = df_list[df_key][['ParkName', 'Zipcode', 'Location 1']]\n",
    "            df = df.dropna()\n",
    "            print(df.head(3))\n",
    "            print(df.dtypes)\n",
    "            #pickleDataFrame(df,'store/public_park.pkl')  \n",
    "        elif(df_key == 'landmarks'):\n",
    "            df = df_list[df_key][['Name', 'the_geom']]\n",
    "            df = df.dropna()\n",
    "            print(df.head(3))\n",
    "            print(df.dtypes)\n",
    "            #pickleDataFrame(df,'store/landmarks.pkl')\n",
    "        elif(df_key == 'schools'):\n",
    "            df = df_list[df_key][['Campus Name', 'Campus Address', 'Location 1']]\n",
    "            df = df.dropna()\n",
    "            print(df.head(3))\n",
    "            print(df.dtypes)\n",
    "            #pickleDataFrame(df,'store/schools.pkl')\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of files being loaded: 8\n",
      "(37.79374000000007, -122.40145999999999)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_list = ['data/city_facilities_data.csv', 'data/privately_owned_public_open_spaces_data.csv', 'data/colleges_map_data.csv', \t\t\t\t\t'data/public_park_and_open_space_data.csv', 'data/commutershuttles_stops_data.csv', 'data/public_park_data.csv', 'data/landmarks_data.csv', 'data/schools_map_data.csv']\n",
    "    print(\"\\nNumber of files being loaded: %i\" %(len(file_list)))\n",
    "    df_dict = {}\n",
    "    if not os.path.exists('store'):\n",
    "        os.makedirs('store')\n",
    "    \n",
    "    #df_dict['facilities'] = loadData(file_list[0])\n",
    "    df_dict['private_open_spaces'] = loadData(file_list[1])\n",
    "    #df_dict['colleges'] = loadData(file_list[2])\n",
    "    #df_dict['public_open_spaces'] = loadData(file_list[3])\n",
    "    #df_dict['commuter_stops'] = loadData(file_list[4])\n",
    "    #df_dict['public_park'] = loadData(file_list[5])\n",
    "    #df_dict['landmarks'] = loadData(file_list[6])\n",
    "    #df_dict['schools'] = loadData(file_list[7])\n",
    "    preprocessData(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
