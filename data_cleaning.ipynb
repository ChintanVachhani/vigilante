{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to clean, reduce, transform and discretize the supporting data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: This function loads data from a csv file and return a pandas dataframe\n",
    "Parameters: Path to file to be loaded\n",
    "Returns: Pandas dataframe\n",
    "'''\n",
    "def loadData(file):\n",
    "    df = pd.read_csv(file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: This function pickles a pandas dataframe\n",
    "Parameters: Pandas dataframe and path of pickle file\n",
    "Returns: N/A\n",
    "'''\n",
    "def storePickle(df,file):\n",
    "    df.to_pickle(file, compression='gzip', protocol=4)\n",
    "    print(\"Pickling to file - %s complete.\" %file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: This function pickles a pandas dataframe\n",
    "Parameters: Pandas dataframe and path of pickle file\n",
    "Returns: N/A\n",
    "'''\n",
    "def readPickle(file):\n",
    "    df = df.read_pickle(file, compression='gzip')\n",
    "    print(\"Successfully read pickle file - %s to dataframe.\" %file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(df_list):\n",
    "    for df_key in df_list.keys():\n",
    "        if(df_key == 'facilities'):\n",
    "            df = df_list[df_key][['common_name','address','longitude','latitude']]\n",
    "            df = df.dropna()\n",
    "            df['common_name'] = df['common_name'].apply(lambda x: x.lower().strip())\n",
    "            df['address'] = df['address'].apply(lambda x: x.lower().strip())\n",
    "            df.columns = ['name', 'address', \"longitude\", \"latitude\"]\n",
    "            storePickle(df,'store/facilities.pkl')\n",
    "        elif(df_key == 'private_open_spaces'):\n",
    "            df = df_list[df_key][['NAME', 'the_geom', 'LOCATION']]\n",
    "            df = df.dropna()\n",
    "            df['Latitude'] = df['the_geom'].apply(lambda x: float(x[1:-1].split(\",\")[0].strip()))\n",
    "            df['Longitude'] = df['the_geom'].apply(lambda x: float(x[1:-1].split(\",\")[1].strip()))\n",
    "            df = df.drop(['the_geom'], axis=1)\n",
    "            df['NAME'] = df['NAME'].apply(lambda x: x.lower().strip())\n",
    "            df['LOCATION'] = df['LOCATION'].apply(lambda x: x.lower().strip())\n",
    "            df.columns = ['address', 'name', \"latitude\", \"longitude\"]\n",
    "            storePickle(df,'store/private_spaces.pkl')\n",
    "        elif(df_key == 'colleges'):\n",
    "            df = df_list[df_key][['Institution', 'Address', 'Location']]\n",
    "            df = df.dropna()\n",
    "            df['Latitude'] = df['Location'].apply(lambda x: float(x[1:-1].split(\",\")[0].strip()))\n",
    "            df['Longitude'] = df['Location'].apply(lambda x: float(x[1:-1].split(\",\")[1].strip()))\n",
    "            df['Institution'] = df['Institution'].apply(lambda x: x.lower().strip())\n",
    "            df['Address'] = df['Address'].apply(lambda x: x.lower().strip())\n",
    "            df = df.drop(['Location'], axis=1)\n",
    "            df.columns = ['name', 'address', 'latitude', 'longitude']\n",
    "            storePickle(df,'store/colleges.pkl')\n",
    "        elif(df_key == 'public_open_spaces'):\n",
    "            df = df_list[df_key][['ParkName', 'Location 1']]\n",
    "            df = df.dropna()\n",
    "            df['ParkName'] = df['ParkName'].apply(lambda x: x.lower().strip())\n",
    "            df['Address'] = df[\"Location 1\"].apply(lambda x: x.split(\"\\n\")[0].lower().strip())\n",
    "            df['Latitude'] = df[\"Location 1\"].apply(lambda x: float(x.split(\"\\n\")[2][1:-1].split(\",\")[0].strip()))\n",
    "            df['Longitude'] = df[\"Location 1\"].apply(lambda x: float(x.split(\"\\n\")[2][1:-1].split(\",\")[1].strip()))\n",
    "            df = df.drop(['Location 1'], axis=1)\n",
    "            df.columns = ['name', 'address', 'latitude', 'longitude']\n",
    "            storePickle(df,'store/public_open_spaces.pkl')\n",
    "        elif(df_key == 'commuter_stops'):\n",
    "            df = df_list[df_key][['LOCATION', 'LATITUDE', 'LONGITUDE', 'PARKINGTYP']]\n",
    "            df = df.dropna()\n",
    "            df['PARKINGTYP'] = df['PARKINGTYP'].apply(lambda x: x.lower().strip()+\" parking\")\n",
    "            df['LOCATION'] = df['LOCATION'].apply(lambda x: ','.join(x.lower().split(',')[0:2]))\n",
    "            df.columns = ['address','latitude', 'longitude','name']\n",
    "            storePickle(df,'store/commuter_stops.pkl')   \n",
    "        elif(df_key == 'public_park'):\n",
    "            df = df_list[df_key][['ParkName', 'Zipcode', 'Location 1']]\n",
    "            df = df.dropna()\n",
    "            df['ParkName'] = df['ParkName'].apply(lambda x: x.lower().strip())\n",
    "            df['Address'] = df[\"Location 1\"].apply(lambda x: x.split(\"\\n\")[0].lower().strip())\n",
    "            df['Latitude'] = df[\"Location 1\"].apply(lambda x: float(x.split(\"\\n\")[2][1:-1].split(\",\")[0].strip()))\n",
    "            df['Longitude'] = df[\"Location 1\"].apply(lambda x: float(x.split(\"\\n\")[2][1:-1].split(\",\")[1].strip()))\n",
    "            df = df.drop(['Location 1','Zipcode'], axis=1)\n",
    "            df.columns = ['name','address','latitude', 'longitude']\n",
    "            storePickle(df,'store/public_park.pkl')  \n",
    "        elif(df_key == 'landmarks'):\n",
    "            df = df_list[df_key][['Name', 'the_geom']]\n",
    "            df = df.dropna()\n",
    "            df['Name'] = df['Name'].apply(lambda x: x.lower().strip())\n",
    "            df['Latitude'] = df['the_geom'].apply(lambda x: float(x.strip('MULTIPOLYGON ')[3:-3].split(\",\")[0].split(\" \")[1]))\n",
    "            df['Longitude'] = df['the_geom'].apply(lambda x: float(x.strip('MULTIPOLYGON ')[3:-3].split(\",\")[1].split(\" \")[1]))\n",
    "            df = df.drop(['the_geom'],axis=1)\n",
    "            df.columns = ['name','latitude', 'longitude']\n",
    "            storePickle(df,'store/landmarks.pkl')\n",
    "        elif(df_key == 'schools'):\n",
    "            df = df_list[df_key][['Campus Name', 'Campus Address', 'Location 1']]\n",
    "            df = df.dropna()\n",
    "            df['Campus Name'] = df['Campus Name'].apply(lambda x:x.lower().strip())\n",
    "            df['Campus Address'] = df['Campus Address'].apply(lambda x:x.split(',')[0].lower().strip())\n",
    "            df['Latitude'] = df['Location 1'].apply(lambda x: x.split('\\n')[1][1:-1].split(\",\")[0].strip())\n",
    "            df['Longitude'] = df['Location 1'].apply(lambda x: x.split('\\n')[1][1:-1].split(\",\")[1].strip())\n",
    "            df = df.drop(['Location 1'], axis=1)\n",
    "            df.columns = ['name', 'address', 'latitude', 'longitude']\n",
    "            storePickle(df,'store/schools.pkl')\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of files being loaded: 8\n",
      "Pickling to file - store/facilities.pkl complete.\n",
      "Pickling to file - store/private_spaces.pkl complete.\n",
      "Pickling to file - store/colleges.pkl complete.\n",
      "Pickling to file - store/public_open_spaces.pkl complete.\n",
      "Pickling to file - store/commuter_stops.pkl complete.\n",
      "Pickling to file - store/public_park.pkl complete.\n",
      "Pickling to file - store/landmarks.pkl complete.\n",
      "Pickling to file - store/schools.pkl complete.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_list = ['data/city_facilities_data.csv', 'data/privately_owned_public_open_spaces_data.csv', 'data/colleges_map_data.csv', \t\t\t\t\t'data/public_park_and_open_space_data.csv', 'data/commutershuttles_stops_data.csv', 'data/public_park_data.csv', 'data/landmarks_data.csv', 'data/schools_map_data.csv']\n",
    "    print(\"\\nNumber of files being loaded: %i\" %(len(file_list)))\n",
    "    df_dict = {}\n",
    "    if not os.path.exists('store'):\n",
    "        os.makedirs('store')\n",
    "    \n",
    "    df_dict['facilities'] = loadData(file_list[0])\n",
    "    df_dict['private_open_spaces'] = loadData(file_list[1])\n",
    "    df_dict['colleges'] = loadData(file_list[2])\n",
    "    df_dict['public_open_spaces'] = loadData(file_list[3])\n",
    "    df_dict['commuter_stops'] = loadData(file_list[4])\n",
    "    df_dict['public_park'] = loadData(file_list[5])\n",
    "    df_dict['landmarks'] = loadData(file_list[6])\n",
    "    df_dict['schools'] = loadData(file_list[7])\n",
    "    preprocessData(df_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
